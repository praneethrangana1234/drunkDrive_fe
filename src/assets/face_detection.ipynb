{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1de059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5011\n",
      " * Running on http://192.168.140.187:5011\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [01/May/2024 16:49:04] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [01/May/2024 16:49:25] \"GET /start-webcam HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "#working\n",
    "from flask import Flask, Response\n",
    "from flask_cors import CORS  # Import CORS from flask_cors\n",
    "import cv2\n",
    "import face_recognition\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# Initialize Flask application\n",
    "app = Flask(__name__)\n",
    "CORS(app)  # Enable CORS for the Flask app\n",
    "\n",
    "# Function to load known faces and their encodings\n",
    "def load_known_faces(directory):\n",
    "    known_faces = {}\n",
    "    for filename in os.listdir(directory):\n",
    "        image_path = os.path.join(directory, filename)\n",
    "        if os.path.isfile(image_path):\n",
    "            image = face_recognition.load_image_file(image_path)\n",
    "            face_encodings = face_recognition.face_encodings(image)\n",
    "            if face_encodings:\n",
    "                # Use the filename without extension as the person's name\n",
    "                name = os.path.splitext(filename)[0]\n",
    "                known_faces[name] = face_encodings[0]\n",
    "    return known_faces\n",
    "\n",
    "# Directory containing known face images\n",
    "known_faces_directory = \"known_faces\"\n",
    "# Load known faces from directory\n",
    "known_faces = load_known_faces(known_faces_directory)\n",
    "\n",
    "# Directory to save detected face images\n",
    "detected_faces_directory = \"detected_faces\"\n",
    "os.makedirs(detected_faces_directory, exist_ok=True)\n",
    "\n",
    "# Define a minimum buffer (in pixels) from the edges of the frame\n",
    "BUFFER = 20\n",
    "\n",
    "# Padding around the face bounding box (in pixels)\n",
    "PADDING = 20\n",
    "\n",
    "# Desired dimensions for the face image (400x400)\n",
    "DESIRED_DIMENSIONS = (400, 400)\n",
    "\n",
    "# Brightness adjustment factor\n",
    "BRIGHTNESS_FACTOR = 1.2  # Increase brightness by 20%; adjust as needed\n",
    "\n",
    "# Dictionary to keep track of presence status of known persons\n",
    "is_present = {}\n",
    "\n",
    "# Generator function to generate frames with detected faces\n",
    "def generate_detected_frames():\n",
    "    # Initialize video capture from the default webcam (0)\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "  \n",
    "   # address=\"http://192.168.140.45:8080/video\";\n",
    "    #video_capture.open(address)\n",
    "   # video_capture = cv2.VideoCapture()\n",
    "    # Check if the webcam is opened successfully\n",
    "    if not video_capture.isOpened():\n",
    "        yield \"Failed to open the webcam.\", 500\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            # Capture frame-by-frame\n",
    "            ret, frame = video_capture.read()\n",
    "\n",
    "            # If there is a frame, proceed with face recognition\n",
    "            if ret:\n",
    "                # Convert the frame from BGR (OpenCV) to RGB (face_recognition)\n",
    "                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                # Find all face locations and encodings\n",
    "                face_locations = face_recognition.face_locations(rgb_frame)\n",
    "                face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "                # List to hold names for faces in this frame\n",
    "                face_names = []\n",
    "\n",
    "                # Track whether a face is recognized and its associated name\n",
    "                for face_encoding in face_encodings:\n",
    "                    # Initialize name as \"Unknown\"\n",
    "                    name = \"Unknown\"\n",
    "\n",
    "                    # Compare face encoding with known face encodings\n",
    "                    for known_name, known_encoding in known_faces.items():\n",
    "                        if face_recognition.compare_faces([known_encoding], face_encoding, tolerance=0.6)[0]:\n",
    "                            name = known_name\n",
    "                            break\n",
    "                \n",
    "                    face_names.append(name)\n",
    "\n",
    "                # Process the results: save and display the frames\n",
    "                for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "                    # Add padding to the bounding box coordinates\n",
    "                    top = max(top - PADDING, 0)\n",
    "                    right = min(right + PADDING, frame.shape[1])\n",
    "                    bottom = min(bottom + PADDING, frame.shape[0])\n",
    "                    left = max(left - PADDING, 0)\n",
    "                    \n",
    "                    # Check if the face is fully within the frame\n",
    "                    if left > BUFFER and right < frame.shape[1] - BUFFER and top > BUFFER and bottom < frame.shape[0] - BUFFER:\n",
    "                        # If the person was previously absent and is now present, update their image\n",
    "                        if name != \"Unknown\":\n",
    "                            # Check if the person was previously absent\n",
    "                            if name not in is_present or not is_present[name]:\n",
    "                                # Get the region of interest (ROI) of the face\n",
    "                                roi_frame = frame[top:bottom, left:right]\n",
    "\n",
    "                                # Resize the ROI frame for desired dimensions (400x400)\n",
    "                                roi_frame_resized = cv2.resize(roi_frame, DESIRED_DIMENSIONS)\n",
    "\n",
    "                                # Convert the resized image from BGR to HSV color space\n",
    "                                hsv_frame = cv2.cvtColor(roi_frame_resized, cv2.COLOR_BGR2HSV)\n",
    "                                \n",
    "                                # Increase the brightness by multiplying the V channel\n",
    "                                hsv_frame[:, :, 2] = cv2.multiply(hsv_frame[:, :, 2], BRIGHTNESS_FACTOR)\n",
    "                                \n",
    "                                # Convert the HSV frame back to BGR color space\n",
    "                                roi_frame_brightened = cv2.cvtColor(hsv_frame, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "                                # Use the person's name as the filename to replace old images with the same name\n",
    "                                filename = f\"{name}.jpg\"\n",
    "\n",
    "                                # Save the brightened and resized ROI frame (face image) to the detected_faces directory\n",
    "                                cv2.imwrite(os.path.join(detected_faces_directory, filename), roi_frame_brightened)\n",
    "\n",
    "                                # Get the current date and time\n",
    "                                current_datetime = datetime.datetime.now()\n",
    "\n",
    "                                # Construct response string with image name, date, and time\n",
    "                                response_str = f\"Image: {filename}, Date: {current_datetime.date().isoformat()}, Time: {current_datetime.time().isoformat()}\"\n",
    "\n",
    "                                # Yield the response string\n",
    "                                yield response_str + '\\n'\n",
    "\n",
    "                                # Mark the person as present\n",
    "                                is_present[name] = True\n",
    "\n",
    "                    # Draw rectangle around the face for display purposes\n",
    "                    cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "                    # Draw a label with the name below the face for display purposes\n",
    "                    cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 255, 0), cv2.FILLED)\n",
    "                    font = cv2.FONT_HERSHEY_DUPLEX\n",
    "                    cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "                # At the end of the frame processing, set all known persons as absent\n",
    "                # Reset the presence status of names that were not seen in this frame\n",
    "                for name in list(is_present.keys()):\n",
    "                    if name not in face_names:\n",
    "                        is_present[name] = False\n",
    "\n",
    "                # Display the resulting image in a window\n",
    "                cv2.imshow('Video', frame)\n",
    "\n",
    "                # Break the loop on pressing 'q' key\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "           # else:\n",
    "             #   print(\"Failed to capture frame.\")\n",
    "            #    break\n",
    "\n",
    "    except Exception as e:\n",
    "        yield f\"An error occurred: {str(e)}\", 500\n",
    "\n",
    "    # Release the webcam and close all OpenCV windows\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Endpoint to start the webcam and perform face recognition\n",
    "@app.route('/start-webcam', methods=['GET'])\n",
    "def start_webcam():\n",
    "    return Response(generate_detected_frames(), mimetype='text/plain')\n",
    "\n",
    "# Home route\n",
    "@app.route('/')\n",
    "def home():\n",
    "   return \"Welcome to the Face Recognition API. Use the /start-webcam endpoint to start the webcam.\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5011) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbf12e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
